

  *  [#system_overview|System Overview]
  *  [#concurrency    |Concurrency Model]
    <ul>
      <li> [#concurrency_bg  |Background]
    </ul>
  *  [#replication    |Replication and other Integration Issues]

A high-concurrency, optimistic row-level-locking backend for SQLite that
more or less plugs in to the btree.h interface. Goals are:

  *  To run significantly faster than stock SQLite in all important cases, and
  *  To allow an order of magnitude more write concurrency than stock SQLite.

All clients must be within a single process. Databases are robust in the face
of process crashes. At the cost of extra writes and file-system syncs, the
database may also be configured to be robust in the face of operating system
crashes and power failures.

Suitable for use in a server system such as BedrockDB.

There is also a document describing the concurrent [./blink.wiki|b-link tree]
used to store data persistently in the file-system, and a
[./fileformat.wiki|file-format document] describing the structure of the 
various types of files.

<h1 id=system_overview>System Overview</h1>

The system is described here in two parts - the b-tree layer and the 
transaction layer. The b-tree layer differs from the SQLite b-tree 
in that:

  *  No direct support for transactions, sub-transactions or transaction
     rollback is provided. Each key operation (insert/update/delete) is
     immediately visible to all other database users.
  *  Concurrent writers are supported.

MVCC snapshots for readers are supported using the same technique as Postgres:

  *  Appended to each key inserted into the b-tree is a transaction id.
  *  Each key has an optional field for the transaction id of the transaction
     that deletes it from the database.
  *  Transaction ids are 56-bit monotonically increasing integers.
  *  To read the newest available stable snapshot, readers need to know the 
     largest committed transaction id for which all previous transactions
     are completely committed. They may then selectively ignore database
     entries based on the created and deleted transaction ids associated with
     each key.
  *  Writers remove entries and transaction id fields that are no longer
     required lazily, when the page is updated for some other reason.
     To do this they need to know the oldest transaction id that may
     still be being used by a reader as a snapshot id as described in
     the previous bullet point.

A writer does not write directly to the b-tree structures when executing
DML/DDL statements. Instead, new keys are accumulated in private memory
structures until the transaction is ready to commit. Also accumulated are
a list of keys and key-ranges read from the database as part of the
transaction.

The transaction queue contains an entry for each transactions that has
either been committed, or is being committed, sorted in order of transaction
id. A transaction is not added to the transaction queue or assigned a
transaction id until it is certain that it will be committed - that it does 
not conflict with any other transaction. Associated with each transaction
queue entry is the set of database keys that the transaction writes to.

When a writer wishes to commit a transaction it iterates through the 
transaction queue, starting with the entry with a transaction id
one greater than the snapshot id it used while reading the database,
in ascending transaction id order, checking for conflicts. A conflict
is found if the writer's transaction reads a key or range of keys that
was modified by a transaction already in the queue. If the writer
reaches the head of the transaction queue without finding a conflict,
it adds its own transaction to the end of the queue and in doing so
assigns itself a transaction id. It then writes its keys to the database.

<h1 id=concurrency>Concurrency Model</h1>

<h2 id=concurrency_bg>Background</h2>

Until somewhere around 2010, concurrency in SQL database systems was much
simpler. Transactions were in most cases allowed to proceed concurrently so
long as they did not write to the same rows, or cause database constraint
violations. This is often termed <b>snapshot isolation</b>. Although this is 
simpler to implement and imposes relatively little overhead, it turns out to be
quite difficult to use, as concurrent combinations of transactions that
function correctly when run independently may malfunction.

<pre>
    CREATE TABLE marbles(id INTEGER PRIMARY KEY, color);
    INSERT INTO marbles VALUES(1, 'white'), (2, 'black'), (3, 'white'), (4, 'black');
</pre>

And two transactions, one that changes the color of all marbles to white, and
one that changes all marbles to black:

<pre>
    -- Transaction 1:
    UPDATE marbles SET color='white' WHERE color='black';
</pre>

<pre>
    -- Transaction 2:
    UPDATE marbles SET color='black' WHERE color='white';
</pre>

Intuitively, after running both of the transactions above concurrently, there
are two possible outcomes - either all of the marbles are white or all of the
marbles are black. However, with snapshot isolation there is a third
possibility - that the color of each marble has been changed, leaving half
white and half black.

Modern systems implement <b>serializable</b> isolation, which does not allow
for this third possibility. Under serializable isolation, a set of
transactions may only be committed if the same transactions may be executed
in some serial order producing results consistent with the final and all
visible interim states of the database produced by concurrent execution. The
usual way to model this is as a graph, where each node is a transaction, and
each directly edge represents a dependency. There are two types of dependency
between transactions:

  *  a <b>dependency</b> which occurs when transaction B reads data written
     by transaction A. In this case transaction B must occur after transaction
     A in the serialization order.

  *  an <b>anti-dependency</b> which occurs when transaction A reads data
     that is overwritten by transaction B. In this case transaction A must
     occur before transaction B in the serialization order.

when a transaction is to be committed, it is added to the directed graph. If
this creates a cycle in the graph, the transaction may not be committed.

One quirk in this is that read-only transactions must also be added to the
graph and be validated before "committing". Results returned by a
read-transaction that does not pass validation must be considered suspect.
For example, consider the following two transactions:

<pre>
    -- T1:
    UPDATE marbles SET color='white';
</pre>

<pre>
    -- T2:
    INSERT INTO marbles VALUES(NULL, 'black');
</pre>

The final state of the database is that it contains one black marble, and the
rest are white. This implies that there is an anti-dependency between T1 and T2
- T1 read data that was later overwritten by T2, so T1 must occur before T2 in
the serialization order:

<verbatim type="pikchr center">
circle "T1" ; arrow ; circle "T2"
</verbatim>

In the above diagram, the arrow runs in the direction of time. The graph
indicates that T2 must occur after T1 in the serialization order.

Say there is also a read-only transaction running:
<pre>
  -- T3:
  SELECT * FROM marbles;
</pre>

If, by some quirk of the system, saw the effects of T2 but not T1 (a mix of
black and white marbles plus the new black marble added by T2), then it would
have a dependency on T2 but an anti-dependency on T1:

<verbatim type="pikchr center">
T3: circle "T3"
T1: circle "T1" at T3 + (-0.5,0.7) ; arrow ; T2: circle "T2"
arrow from T2.sw to T3.ne
arrow from T3.nw to T1.se
</verbatim>

In this case, one of more of T1, T2 or T3 would have to be rolled back. Even
though the both the final state and interim state of the database observed
by T3 are possible outcomes of executing T1 and T2 in serial, they are not
consistent with each other and therefore a violation of serializable
isolation.

A full implementation of such a graph is considered too expensive in 
practice. And so all current systems implement some compromise that allows
for some number of false-positive conflict detections.

<h2>HC-Tree Approach</h2>



<h1 id=replication>Replication and other Integration Issues</h1>

<i> In which it is discussed how this fits in with streaming replication
and bootstrapping a new node</i>


